{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装下载spacy和必要的库\n",
    "\n",
    "```bash\n",
    "# 确保已经安装了中文模型\n",
    "\n",
    "pip install spacy\n",
    "python -m spacy download zh_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 加载中文模型\n",
    "nlp = spacy.load(\"zh_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怎么\n",
      "解锁\n",
      "宠物\n",
      "的\n",
      "家\n",
      "？\n"
     ]
    }
   ],
   "source": [
    "# 使用nlp对象处理一段文本并生成doc实例\n",
    "doc = nlp(\"怎么解锁宠物的家？\")\n",
    "\n",
    "# 遍历doc实例中的词符\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "宠物 NOUN nmod:assmod\n",
      "的 PART case\n",
      "家 NOUN nsubj\n",
      "在 VERB dep\n",
      "哪 PRON dobj\n",
      "啊 PART discourse\n",
      "？ PUNCT ROOT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'宠物的家在哪啊？')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词的属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:    [0, 1, 2, 3, 4, 5]\n",
      "Text:     ['怎么', '解锁', '宠物', '的', '家', '？']\n",
      "is_alpha: [True, True, True, True, True, False]\n",
      "is_punct: [False, False, False, False, False, True]\n",
      "like_num: [False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"怎么解锁宠物的家？\")\n",
    "\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:\", [token.is_punct for token in doc])\n",
    "print(\"like_num:\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP模型训练\n",
    "\n",
    "使spaCy可以_从语境中_抽取到语言学属性的模型\n",
    "\n",
    " - 词性标注\n",
    " - 依存关系解析\n",
    " - 命名实体识别\n",
    "\n",
    "从标注过的文本中训练而来\n",
    "\n",
    "可以用更多的标注数据来更新模型，优化抽取结果\n",
    "\n",
    "```\n",
    "python -m spacy download zh_core_web_sm\n",
    "```\n",
    "\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怎么 ADV\n",
      "解锁 VERB\n",
      "宠物 NOUN\n",
      "的 PART\n",
      "家 NOUN\n",
      "？ PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 读取小版本的中文流程\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"怎么解锁宠物的家？\")\n",
    "\n",
    "# 遍历词符\n",
    "for token in doc:\n",
    "    # Print the text and the predicted part-of-speech tag\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 依存关系解析\n",
    "\n",
    "除了词性分析以外，我们还可以预测词与词之间的关系。比如一个词是某一个句子或者物体的主语。\n",
    "\n",
    "`.dep_`属性返回预测的依存关系标注。\n",
    "\n",
    "`.head`属性返回句法头词符。你可以认为这是词在句子中所依附的母词符。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怎么 ADV advmod 解锁\n",
      "解锁 VERB ROOT 解锁\n",
      "宠物 NOUN nmod:assmod 家\n",
      "的 PART case 宠物\n",
      "家 NOUN dobj 解锁\n",
      "？ PUNCT punct 解锁\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 依存关系的定义\n",
    "\n",
    "| Label     | Description | Example |\n",
    "| --------- | ----------- | ------- |\n",
    "| **nsubj** | 名词主语    |        |\n",
    "| **dobj**  | 目的语      | 解锁  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 命名实体识别\n",
    "\n",
    "命名实体是那些被赋予了名字的真实世界的物体，比如一个人、一个组织或者一个国家。\n",
    "\n",
    "从 `doc.ents` 中可以读取命名实体识别模型预测出的所有命名实体。\n",
    "\n",
    "它会返回一个 `Span` 实例的遍历器，我们可以打印出实体文本和用 `.label_` 属性来打印出实体标注。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理文本\n",
    "doc = nlp(\"怎么解锁宠物的家？\")\n",
    "\n",
    "# 遍历识别出的实体\n",
    "for ent in doc.ents:\n",
    "    # 打印实体文本及其标注\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "奥比岛 PERSON\n",
      "大洋 LOC\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 确保已经安装了中文模型\n",
    "# pip install spacy\n",
    "# python -m spacy download zh_core_web_sm\n",
    "\n",
    "# 加载中文模型\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 使用包含命名实体的文本\n",
    "doc = nlp(\"奥比岛在一个一望无际的大洋上。\")\n",
    "\n",
    "# 遍历识别出的实体\n",
    "for ent in doc.ents:\n",
    "    # 打印实体文本及其标注\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adverb'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 获得标注和标签定义\n",
    "\n",
    "一个小诀窍是可以用 `spacy.explain` 这个帮手函数 来快速获得大部分常见的标注和标签定义。\n",
    "\n",
    "举个例子，可能很多人不知道 \"GPE\" 代表的地理政治实体（geopolitical entity）的意思， 但调用 `spacy.explain` 我们就知道这是指国家、城市和州省。\n",
    "\n",
    "同样这个方法也适用于词性标注和依存关系标注。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "怎么 ADV advmod 解锁\n",
    "解锁 VERB ROOT 解锁\n",
    "宠物 NOUN nmod:assmod 家\n",
    "的 PART case 宠物\n",
    "家 NOUN dobj 解锁\n",
    "？ PUNCT punct 解锁\n",
    "\"\"\"\n",
    "\n",
    "# spacy.explain(\"ADV\")\n",
    "# spacy.explain(\"advmod\")\n",
    "# spacy.explain(\"VERB\")\n",
    "# spacy.explain(\"ROOT\")\n",
    "spacy.explain(\"assmod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于匹配的规则\n",
    "\n",
    "本节课我们一起来学习spaCy的matcher， 用它来写一些规则来寻找文本中的目标词汇和短语。\n",
    "\n",
    "为何不直接用正则表达式？\n",
    "\n",
    "- 我们是在`Doc`对象中而不是直接在字符串上做匹配\n",
    "- 我们是在词符及其属性中做匹配\n",
    "- 我们会用到模型的预测结果\n",
    "- 举个例子，\"duck\" (动词) vs. \"duck\" (名词)是不一样的（\"duck\"名词意思是鸭子，而动词是闪避的意思）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匹配的模板是一些列表，列表的每一个元素是一个字典。 每个字典代表一个词符，键值是词符属性名，映射到对应的目标值上面。\n",
    "\n",
    "这个例子里我们要找两个文本为\"iPhone\"和\"X\"的词符。\n",
    "\n",
    "我们也可以去匹配其它的词符属性。这里我们找两个小写形式为\"iphone\"和\"x\"的词符。\n",
    "\n",
    "我们甚至可以直接调用模型的预测结果来写规则。这里我们找一个词根为\"buy\"且后面为名词的词符。 词根是词的基础形式，所以这个模板会匹配到诸如\"buying milk\"或者\"bought flowers\"这样的短语。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用模板我们首先从spacy.matcher中导入matcher。\n",
    "\n",
    "我们还要读取一个流程创建nlp实例。\n",
    "\n",
    "用模型分享出来的词汇表nlp.vocab来初始化matcher。 我们后面会详细介绍这一块，现在只要记得一定要传入这个词汇表就好了。\n",
    "\n",
    "matcher.add方法可以用来添加一个模板。第一个参数是唯一的ID用来识别匹配的是哪一个模板。 第二个参数是一个模板的列表。\n",
    "\n",
    "要在文本中匹配模板，我们可以在任何doc中调用matcher。\n",
    "\n",
    "这样就会返回所有的匹配结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模板匹配\n",
    "\n",
    "- 一个元素是字典的列表，一个词符是一个元素\n",
    "- 匹配词符的完全一致的文字\n",
    "\n",
    "```\n",
    "[{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "```\n",
    "\n",
    "- 匹配词汇属性\n",
    "\n",
    "```\n",
    "[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
    "```\n",
    "\n",
    "- 匹配任意的词符属性\n",
    "\n",
    "```\n",
    "[{\"LEMMA\": \"buy\"}, {\"POS\": \"NOUN\"}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Matcher (1)：基于规则的匹配抽取\n",
    "\n",
    "import spacy\n",
    "\n",
    "# 导入Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建nlp实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模型分享出的vocab初始化matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给matcher加入模板\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"即将上市的iPhone X发布日期被泄露了\")\n",
    "\n",
    "# 在doc上面调用matcher\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `match_id`: 模板名的哈希值\n",
    "- `start`: 匹配到的跨度的起始索引\n",
    "- `end`: 匹配到的跨度的终止索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "# 使用Matcher (2)：基于规则的匹配抽取\n",
    "\n",
    "# 在doc上调用matcher\n",
    "doc = nlp(\"即将上市的iPhone X发布日期被泄露了\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 例子：模板匹配1\n",
    "\n",
    "这是一个用到词汇属性的更复杂的匹配模板的例子。\n",
    "\n",
    "我们要找五个词符：\n",
    "\n",
    "一个只含有数字的词符；\n",
    "\n",
    "三个匹配到\"国际\", \"足联\"和\"世界杯\"的词符；\n",
    "\n",
    "以及一个标点符号词符。\n",
    "\n",
    "这个模板最后可以匹配到\"2018国际足联世界杯：\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018国际足联世界杯：\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 导入Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建nlp实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模型分享出的vocab初始化matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给matcher加入模板\n",
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"国际\"},\n",
    "    {\"LOWER\": \"足联\"},\n",
    "    {\"LOWER\": \"世界杯\"},\n",
    "    {\"IS_PUNCT\": True}\n",
    "]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"2018国际足联世界杯：法国队赢了！\")\n",
    "\n",
    "# 在doc上面调用matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 例子：模板匹配2\n",
    "\n",
    "这个例子中我们寻找两个词符：\n",
    "\n",
    "一个词根是\"喜欢\"的动词，后面跟着一个名词。\n",
    "\n",
    "这个模板最后可以匹配到\"喜欢狗\"和\"喜欢猫\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "喜欢狗\n",
      "喜欢猫\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建nlp实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模型分享出的vocab初始化matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给matcher加入模板\n",
    "pattern = [\n",
    "    {\"POS\": \"VERB\"},\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "matcher.add(\"PATTERN_NAME\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"我喜欢狗但我更喜欢猫。\")\n",
    "\n",
    "# 在doc上面调用matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用运算符和量词来定义一个词符应该被匹配几次。 我们可以用\"OP\"这个关键词来添加它们。\n",
    "\n",
    "在这里\"?\"运算符使相应的判断词符变为可选， 所以我们会匹配到一个词根为\"买\"的词符，一个可选的数词和一个名词。\n",
    "\n",
    "> 注意：中文分词\"LEMMA\"有错误，导致不能直接输出动词和名词形式的模板输出。问题待解决……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "买个肉夹馍\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# 读取一个流程，创建nlp实例\n",
    "nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# 用模型分享出的vocab初始化matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# 给matcher加入模板\n",
    "pattern = [\n",
    "    {\"TEXT\": \"买\"},\n",
    "    {\"POS\": \"NUM\", \"OP\": \"?\"},  # 可选: 匹配0次或者1次\n",
    "    {\"POS\": \"NOUN\"}\n",
    "]\n",
    "matcher.add(\"PATTERN_NAME\", [pattern])\n",
    "\n",
    "# 处理文本\n",
    "doc = nlp(\"我买个肉夹馍。我还要买凉皮。\")\n",
    "\n",
    "# 在doc上面调用matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# 遍历所有的匹配结果\n",
    "for match_id, start, end in matches:\n",
    "    # 获取匹配的跨度\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"OP\"可以有以下四种值：\n",
    "\n",
    "\"!\"用来否定一个词符，所以它一次也不能被匹配。\n",
    "\n",
    "\"?\"用来将一个词符变为可选，可以匹配0次或者1次。\n",
    "\n",
    "\"+\"用来匹配目标词符1次或更多次。\n",
    "\n",
    "最后，\"*\"用来匹配目标词符0次或更多次。\n",
    "\n",
    "运算符可以大大加模板的威力，当然也带来了更多的复杂度。我们要学会善用它。\n",
    "\n",
    "\n",
    "\n",
    "| 例子          | 说明               |\n",
    "| ------------- | ------------------ |\n",
    "| `{\"OP\": \"!\"}` | 否定: 0次匹配      |\n",
    "| `{\"OP\": \"?\"}` | 可选: 0次或1次匹配 |\n",
    "| `{\"OP\": \"+\"}` | 1次或更多次匹配    |\n",
    "| `{\"OP\": \"*\"}` | 0次或更多次匹配    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
